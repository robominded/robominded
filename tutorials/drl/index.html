<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script> 

<!------------------These relative links MUST be modified ---v-------------------------->
<!------------------These relative links MUST be modified --vvv------------------------->
<!------------------These relative links MUST be modified -vvvvv------------------------->

<script> $(function(){ $("#header_tutorials").load("../../pageElements/tutorials_meta_info.html"); }); </script> 
<script> $(function(){ $("#include_header").load("../../pageElements/header.html"); }); </script> 
<script> $(function(){ $("#include_footer").load("../../pageElements/footer.html"); }); </script> 
<script>hljs.highlightAll();</script>
<title>roboMind</title>
<div id="header_tutorials"></div>
</head>

<body>
<div id="include_header"></div> 


<div  class="page">
<ol style ="margin: 10px; list-style: none;" class="links">
    <li> <b>Value Iteration</b> solves a mathematical optimization problem using 
        dynamic programming to find optimal policy. Although it is not a 
        learning approach and does not scale ot problems with large spaces, 
        its concepts are fundamental for reinforcement learning. <br>
        Click on<a href="value_iteration.html">Value Iteration</a>  for more.
        <hr>
    </li>
    <li> <b>SARSA</b> is a model-free reinforcement learning algorithm. It  uses temporal 
        difference learning to optimize its estimation of the state-action values 
        (Q-values). Further, it employes an action selection algorithm that relies on
        Q-values such as epsilon greedy. <br> Click on 
        <a href="sarsa.html"> SARSA</a>  for more. 
        <hr> 
    </li>
    <li> <b> Q-learning</b> is similar to SARSA, but it is an off-policy 
        algorithm, which means that its behavior and target policies are different. In particular, 
        The Q-learning's update rule selects the action from the next state with the maximum 
        Q-value which is not necessarily the one chosen by  the epsilon$-greedy algorithm as 
        in SARSA. <br>
        Click on <a href="qlearning.html"> Q Learning</a>  for more. 
        <hr>
    </li>
    <li> <a href="deep_sarsa.html"> Policy Gradient (REINFORCE)</a>  </li>
    <li> <a href="deep_sarsa.html"> Deep SARSA</a>  </li>
</ol>

</div>





<!-- page footer -->
<div id="include_footer"></div>

</body>
</html>

